{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d95781f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e619e77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './datasets/'\n",
    "\n",
    "train_features_df = pd.read_csv(os.path.join(DATA_PATH, 'train_features.csv'))\n",
    "test_features_df = pd.read_csv(os.path.join(DATA_PATH, 'test_features.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8208bfd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>month</th>\n",
       "      <th>B2_mean</th>\n",
       "      <th>B2_std</th>\n",
       "      <th>B2_min</th>\n",
       "      <th>B2_max</th>\n",
       "      <th>B2_median</th>\n",
       "      <th>B3_mean</th>\n",
       "      <th>B3_std</th>\n",
       "      <th>B3_min</th>\n",
       "      <th>...</th>\n",
       "      <th>B11_min</th>\n",
       "      <th>B11_max</th>\n",
       "      <th>B11_median</th>\n",
       "      <th>B12_mean</th>\n",
       "      <th>B12_std</th>\n",
       "      <th>B12_min</th>\n",
       "      <th>B12_max</th>\n",
       "      <th>B12_median</th>\n",
       "      <th>Crop</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_t4Tmmn_Jan</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2530.2866</td>\n",
       "      <td>10.403985</td>\n",
       "      <td>2501.0</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>2529.0</td>\n",
       "      <td>2249.9440</td>\n",
       "      <td>24.179565</td>\n",
       "      <td>2187.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>1497.0</td>\n",
       "      <td>1434.0</td>\n",
       "      <td>2978.0210</td>\n",
       "      <td>241.32278</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>3596.0</td>\n",
       "      <td>2988.0</td>\n",
       "      <td>Rubber</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_h14T0B_Jan</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2573.0923</td>\n",
       "      <td>8.352156</td>\n",
       "      <td>2555.0</td>\n",
       "      <td>2605.0</td>\n",
       "      <td>2573.0</td>\n",
       "      <td>2267.8613</td>\n",
       "      <td>15.180915</td>\n",
       "      <td>2220.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>1446.0</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>2664.9092</td>\n",
       "      <td>129.55461</td>\n",
       "      <td>2061.0</td>\n",
       "      <td>3011.0</td>\n",
       "      <td>2675.0</td>\n",
       "      <td>Rubber</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID month    B2_mean     B2_std  B2_min  B2_max  B2_median  \\\n",
       "0  ID_t4Tmmn_Jan   Jan  2530.2866  10.403985  2501.0  2600.0     2529.0   \n",
       "1  ID_h14T0B_Jan   Jan  2573.0923   8.352156  2555.0  2605.0     2573.0   \n",
       "\n",
       "     B3_mean     B3_std  B3_min  ...  B11_min  B11_max  B11_median   B12_mean  \\\n",
       "0  2249.9440  24.179565  2187.0  ...   1271.0   1497.0      1434.0  2978.0210   \n",
       "1  2267.8613  15.180915  2220.0  ...   1342.0   1446.0      1402.0  2664.9092   \n",
       "\n",
       "     B12_std  B12_min  B12_max  B12_median    Crop  class  \n",
       "0  241.32278   1977.0   3596.0      2988.0  Rubber      3  \n",
       "1  129.55461   2061.0   3011.0      2675.0  Rubber      3  \n",
       "\n",
       "[2 rows x 59 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb4c7748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (7433, 59)\n",
      "Test dataset shape: (2201, 57)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset shape: {train_features_df.shape}\")\n",
    "print(f\"Test dataset shape: {test_features_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7286275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique IDs in test data: 282\n",
      "\n",
      "Encoded labels:\n",
      "Cocoa: 0\n",
      "Palm: 1\n",
      "Rubber: 2\n"
     ]
    }
   ],
   "source": [
    "# Extract base IDs (without month)\n",
    "train_features_df['base_id'] = train_features_df['ID'].str.split('_').str[1]\n",
    "test_features_df['base_id'] = test_features_df['ID'].str.split('_').str[1]\n",
    "\n",
    "# Create submission ID format (ID_XXXXX)\n",
    "train_features_df['submission_id'] = 'ID_' + train_features_df['base_id']\n",
    "test_features_df['submission_id'] = 'ID_' + test_features_df['base_id']\n",
    "\n",
    "print(f\"Number of unique IDs in test data: {test_features_df['base_id'].nunique()}\")\n",
    "\n",
    "# Encode target labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "train_features_df['Crop_encoded'] = label_encoder.fit_transform(train_features_df['Crop'])\n",
    "print(\"\\nEncoded labels:\")\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\"{label}: {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cfd38ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the month column to numerical values\n",
    "month_mapping = {\n",
    "    'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,\n",
    "    'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12\n",
    "}\n",
    "\n",
    "train_features_df['month_num'] = train_features_df['month'].map(month_mapping)\n",
    "test_features_df['month_num'] = test_features_df['month'].map(month_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a1709b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Feature Engineering\n",
    "def create_enhanced_features(df):\n",
    "    \"\"\"Create advanced features from the spectral bands using band statistics\"\"\"\n",
    "    \n",
    "    # -------- Basic Vegetation Indices --------\n",
    "    # NDVI (Normalized Difference Vegetation Index)\n",
    "    df['NDVI'] = (df['B8_mean'] - df['B4_mean']) / (df['B8_mean'] + df['B4_mean'])\n",
    "    \n",
    "    # EVI (Enhanced Vegetation Index)\n",
    "    df['EVI'] = 2.5 * ((df['B8_mean'] - df['B4_mean']) / (df['B8_mean'] + 6 * df['B4_mean'] - 7.5 * df['B2_mean'] + 1))\n",
    "    \n",
    "    # SAVI (Soil Adjusted Vegetation Index)\n",
    "    L = 0.5  # soil brightness correction factor\n",
    "    df['SAVI'] = ((df['B8_mean'] - df['B4_mean']) / (df['B8_mean'] + df['B4_mean'] + L)) * (1 + L)\n",
    "    \n",
    "    # NDWI (Normalized Difference Water Index)\n",
    "    df['NDWI'] = (df['B3_mean'] - df['B8_mean']) / (df['B3_mean'] + df['B8_mean'])\n",
    "    \n",
    "    # NDBI (Normalized Difference Built-up Index)\n",
    "    df['NDBI'] = (df['B11_mean'] - df['B8_mean']) / (df['B11_mean'] + df['B8_mean'])\n",
    "    \n",
    "    # NBR (Normalized Burn Ratio)\n",
    "    df['NBR'] = (df['B8_mean'] - df['B12_mean']) / (df['B8_mean'] + df['B12_mean'])\n",
    "    \n",
    "    # NDRE (Normalized Difference Red Edge)\n",
    "    df['NDRE'] = (df['B8_mean'] - df['B5_mean']) / (df['B8_mean'] + df['B5_mean'])\n",
    "    \n",
    "    # ------------ Additional Advanced Indices ----------------------\n",
    "    \n",
    "    # MTCI (MERIS Terrestrial Chlorophyll Index) - sensitive to chlorophyll content\n",
    "    df['MTCI'] = (df['B8_mean'] - df['B5_mean']) / (df['B5_mean'] - df['B4_mean'])\n",
    "    \n",
    "    # MCARI (Modified Chlorophyll Absorption Ratio Index)\n",
    "    df['MCARI'] = ((df['B5_mean'] - df['B4_mean']) - 0.2 * (df['B5_mean'] - df['B3_mean'])) * (df['B5_mean'] / df['B4_mean'])\n",
    "    \n",
    "    # GNDVI (Green Normalized Difference Vegetation Index)\n",
    "    df['GNDVI'] = (df['B8_mean'] - df['B3_mean']) / (df['B8_mean'] + df['B3_mean'])\n",
    "    \n",
    "    # PSRI (Plant Senescence Reflectance Index) - good for identifying crop maturity\n",
    "    df['PSRI'] = (df['B4_mean'] - df['B3_mean']) / df['B8_mean']\n",
    "    \n",
    "    # SIPI (Structure Insensitive Pigment Index)\n",
    "    df['SIPI'] = (df['B8_mean'] - df['B2_mean']) / (df['B8_mean'] - df['B4_mean'])\n",
    "    \n",
    "    # ARVI (Atmospherically Resistant Vegetation Index)\n",
    "    df['ARVI'] = (df['B8_mean'] - (2 * df['B4_mean'] - df['B2_mean'])) / (df['B8_mean'] + (2 * df['B4_mean'] - df['B2_mean']))\n",
    "    \n",
    "    # MSI (Moisture Stress Index)\n",
    "    df['MSI'] = df['B11_mean'] / df['B8_mean']\n",
    "    \n",
    "    # NDMI (Normalized Difference Moisture Index)\n",
    "    df['NDMI'] = (df['B8_mean'] - df['B11_mean']) / (df['B8_mean'] + df['B11_mean'])\n",
    "    \n",
    "    # CIrededge (Chlorophyll Index Red-Edge)\n",
    "    df['CIrededge'] = (df['B8_mean'] / df['B5_mean']) - 1\n",
    "    \n",
    "    # CIgreen (Chlorophyll Index Green)\n",
    "    df['CIgreen'] = (df['B8_mean'] / df['B3_mean']) - 1\n",
    "    \n",
    "    # Band ratios and combinations\n",
    "    df['B8_B4'] = df['B8_mean'] / df['B4_mean']\n",
    "    df['B11_B8'] = df['B11_mean'] / df['B8_mean']\n",
    "    df['B2_B3'] = df['B2_mean'] / df['B3_mean']\n",
    "    df['B4_B3'] = df['B4_mean'] / df['B3_mean']\n",
    "    df['B5_B4'] = df['B5_mean'] / df['B4_mean']\n",
    "    df['B6_B5'] = df['B6_mean'] / df['B5_mean']\n",
    "    df['B7_B6'] = df['B7_mean'] / df['B6_mean']\n",
    "    df['B8A_B8'] = df['B8A_mean'] / df['B8_mean']\n",
    "    df['B11_B12'] = df['B11_mean'] / df['B12_mean']\n",
    "    \n",
    "    # ------- Texture-related features (using std values) --------\n",
    "    # Variance ratios (using std as a proxy for variance)\n",
    "    df['var_vis_ratio'] = (df['B2_std'] + df['B3_std'] + df['B4_std']) / 3\n",
    "    df['var_nir_ratio'] = (df['B8_std'] + df['B8A_std']) / 2\n",
    "    df['var_swir_ratio'] = (df['B11_std'] + df['B12_std']) / 2\n",
    "    df['var_rededge_ratio'] = (df['B5_std'] + df['B6_std'] + df['B7_std']) / 3\n",
    "    \n",
    "    # Statistical features using existing statistics\n",
    "    df['mean_vis'] = (df['B2_mean'] + df['B3_mean'] + df['B4_mean']) / 3\n",
    "    df['mean_nir'] = (df['B8_mean'] + df['B8A_mean']) / 2\n",
    "    df['mean_swir'] = (df['B11_mean'] + df['B12_mean']) / 2\n",
    "    df['mean_rededge'] = (df['B5_mean'] + df['B6_mean'] + df['B7_mean']) / 3\n",
    "    \n",
    "    df['min_vis'] = np.minimum.reduce([df['B2_min'], df['B3_min'], df['B4_min']])\n",
    "    df['min_nir'] = np.minimum.reduce([df['B8_min'], df['B8A_min']])\n",
    "    df['min_swir'] = np.minimum.reduce([df['B11_min'], df['B12_min']])\n",
    "    df['min_rededge'] = np.minimum.reduce([df['B5_min'], df['B6_min'], df['B7_min']])\n",
    "    \n",
    "    df['max_vis'] = np.maximum.reduce([df['B2_max'], df['B3_max'], df['B4_max']])\n",
    "    df['max_nir'] = np.maximum.reduce([df['B8_max'], df['B8A_max']])\n",
    "    df['max_swir'] = np.maximum.reduce([df['B11_max'], df['B12_max']])\n",
    "    df['max_rededge'] = np.maximum.reduce([df['B5_max'], df['B6_max'], df['B7_max']])\n",
    "    \n",
    "    df['range_vis'] = df['max_vis'] - df['min_vis']\n",
    "    df['range_nir'] = df['max_nir'] - df['min_nir']\n",
    "    df['range_swir'] = df['max_swir'] - df['min_swir']\n",
    "    df['range_rededge'] = df['max_rededge'] - df['min_rededge']\n",
    "    \n",
    "    # Median-based features\n",
    "    df['median_vis'] = (df['B2_median'] + df['B3_median'] + df['B4_median']) / 3\n",
    "    df['median_nir'] = (df['B8_median'] + df['B8A_median']) / 2\n",
    "    df['median_swir'] = (df['B11_median'] + df['B12_median']) / 2\n",
    "    df['median_rededge'] = (df['B5_median'] + df['B6_median'] + df['B7_median']) / 3\n",
    "    \n",
    "    # Median to mean ratios (can indicate skewness)\n",
    "    df['median_mean_ratio_vis'] = df['median_vis'] / df['mean_vis']\n",
    "    df['median_mean_ratio_nir'] = df['median_nir'] / df['mean_nir']\n",
    "    df['median_mean_ratio_swir'] = df['median_swir'] / df['mean_swir']\n",
    "    df['median_mean_ratio_rededge'] = df['median_rededge'] / df['mean_rededge']\n",
    "    \n",
    "    # Seasonal features - sine and cosine transformations\n",
    "    # Check if month_num exists, otherwise create from month\n",
    "    if 'month_num' not in df.columns:\n",
    "        # Assuming month is already a numeric value from 1-12\n",
    "        df['month_num'] = df['month']\n",
    "        \n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month_num'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month_num'] / 12)\n",
    "    \n",
    "    # Season categorical (1=Winter, 2=Spring, 3=Summer, 4=Fall)\n",
    "    df['season'] = ((df['month_num'] % 12 + 3) // 3) % 4 + 1\n",
    "    \n",
    "    # Growth phase approximation (based on month in tropical regions)\n",
    "    # This is a simplified approximation and we could be refine it later with actual crop calendars\n",
    "    # For West Africa: roughly planting in April-May, growing in June-Sept, harvesting in Oct-Dec\n",
    "    conditions = [\n",
    "        (df['month_num'].isin([4, 5])),  # Planting\n",
    "        (df['month_num'].isin([6, 7, 8, 9])),  # Growing\n",
    "        (df['month_num'].isin([10, 11, 12])),  # Harvesting\n",
    "        (df['month_num'].isin([1, 2, 3]))  # Post-harvest/fallow\n",
    "    ]\n",
    "    choices = [1, 2, 3, 4]\n",
    "    df['growth_phase'] = np.select(conditions, choices, default=0)\n",
    "    \n",
    "    # Additional features using std values\n",
    "    df['std_to_mean_B4'] = df['B4_std'] / df['B4_mean']  # Red band variability\n",
    "    df['std_to_mean_B8'] = df['B8_std'] / df['B8_mean']  # NIR band variability\n",
    "    df['std_to_mean_B11'] = df['B11_std'] / df['B11_mean']  # SWIR band variability\n",
    "    \n",
    "    # Ratio of max to min (dynamic range)\n",
    "    df['dynamic_range_B4'] = df['B4_max'] / df['B4_min']\n",
    "    df['dynamic_range_B8'] = df['B8_max'] / df['B8_min']\n",
    "    df['dynamic_range_B11'] = df['B11_max'] / df['B11_min']\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = create_enhanced_features(train_features_df)\n",
    "test_df = create_enhanced_features(test_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "23a3e9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_features(df):\n",
    "    \"\"\"Add features that are missing from the current implementation\"\"\"\n",
    "    \n",
    "    # 1. Additional Vegetation Indices\n",
    "    \n",
    "    # MSAVI (Modified Soil Adjusted Vegetation Index)\n",
    "    # MSAVI = (2 * NIR + 1 - sqrt((2 * NIR + 1)^2 - 8 * (NIR - RED))) / 2\n",
    "    df['MSAVI'] = (2 * df['B8_mean'] + 1 - np.sqrt((2 * df['B8_mean'] + 1)**2 - 8 * (df['B8_mean'] - df['B4_mean']))) / 2\n",
    "    \n",
    "    # EVI2 (Enhanced Vegetation Index 2) - simpler version of EVI\n",
    "    df['EVI2'] = 2.5 * ((df['B8_mean'] - df['B4_mean']) / (df['B8_mean'] + 2.4 * df['B4_mean'] + 1))\n",
    "    \n",
    "    # IRECI (Inverted Red-Edge Chlorophyll Index)\n",
    "    df['IRECI'] = (df['B7_mean'] - df['B4_mean']) / (df['B5_mean'] / df['B6_mean'])\n",
    "    \n",
    "    # S2REP (Sentinel-2 Red-Edge Position)\n",
    "    df['S2REP'] = 705 + 35 * ((df['B7_mean'] + df['B4_mean']) / 2 - df['B5_mean']) / (df['B6_mean'] - df['B5_mean'])\n",
    "    \n",
    "    # 2. Texture and Variance Metrics\n",
    "    \n",
    "    # Coefficient of variation for different spectral regions\n",
    "    df['cv_vis'] = df[['B2_mean', 'B3_mean', 'B4_mean']].std(axis=1) / df[['B2_mean', 'B3_mean', 'B4_mean']].mean(axis=1)\n",
    "    df['cv_nir'] = df[['B8_mean', 'B8A_mean']].std(axis=1) / df[['B8_mean', 'B8A_mean']].mean(axis=1)\n",
    "    df['cv_swir'] = df[['B11_mean', 'B12_mean']].std(axis=1) / df[['B11_mean', 'B12_mean']].mean(axis=1)\n",
    "    df['cv_rededge'] = df[['B5_mean', 'B6_mean', 'B7_mean']].std(axis=1) / df[['B5_mean', 'B6_mean', 'B7_mean']].mean(axis=1)\n",
    "    \n",
    "    # 3. Transformations of existing features\n",
    "    \n",
    "    # Log transformations of key bands\n",
    "    for band in ['B4_mean', 'B8_mean', 'B11_mean']:\n",
    "        df[f'log_{band}'] = np.log1p(df[band])\n",
    "    \n",
    "    # 4. Interaction terms\n",
    "    \n",
    "    # Interaction between NDVI and season\n",
    "    df['NDVI_season'] = df['NDVI'] * df['season']\n",
    "    \n",
    "    # Interaction between NDVI and month\n",
    "    if 'month_num' in df.columns:\n",
    "        df['NDVI_month'] = df['NDVI'] * df['month_num']\n",
    "    \n",
    "    # 5. Additional band ratios and combinations\n",
    "    \n",
    "    # Red-edge position indicators\n",
    "    df['rededge_ratio1'] = df['B5_mean'] / df['B6_mean']\n",
    "    df['rededge_ratio2'] = df['B6_mean'] / df['B7_mean']\n",
    "    df['rededge_ratio3'] = df['B5_mean'] / df['B7_mean']\n",
    "    \n",
    "    # Ratio between different spectral regions\n",
    "    df['vis_nir_ratio'] = df['mean_vis'] / df['mean_nir']\n",
    "    df['nir_swir_ratio'] = df['mean_nir'] / df['mean_swir']\n",
    "    df['vis_swir_ratio'] = df['mean_vis'] / df['mean_swir']\n",
    "    \n",
    "    # 6. LAI approximation\n",
    "    df['LAI_approx'] = 3.618 * df['EVI'] - 0.118\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = add_missing_features(train_df)\n",
    "test_df = add_missing_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3161c6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_temporal_features(df):\n",
    "#     \"\"\"Create features that capture changes across months for the same location\"\"\"\n",
    "    \n",
    "#     # Extract base_id from ID if not already present\n",
    "#     if 'base_id' not in df.columns:\n",
    "#         df['base_id'] = df['ID'].str.split('_').str[1]\n",
    "    \n",
    "#     # Group by base_id\n",
    "#     grouped = df.groupby('base_id')\n",
    "    \n",
    "#     # Create a dictionary to store the new features\n",
    "#     new_features = {}\n",
    "    \n",
    "#     # Initialize the dictionary with empty lists for each new feature\n",
    "#     for feature in ['NDVI_range', 'NDVI_std', 'NDVI_trend', 'EVI_range', 'EVI_std', \n",
    "#                    'B8_range', 'B8_std', 'B4_range', 'B4_std', 'month_count']:\n",
    "#         new_features[feature] = []\n",
    "    \n",
    "#     # Process each base_id group\n",
    "#     for base_id, group in grouped:\n",
    "#         # Sort by month_num to ensure chronological order\n",
    "#         if 'month_num' in group.columns:\n",
    "#             group = group.sort_values('month_num')\n",
    "        \n",
    "#         # Count number of months available\n",
    "#         month_count = len(group)\n",
    "        \n",
    "#         # Calculate range and standard deviation for key indices\n",
    "#         ndvi_range = group['NDVI'].max() - group['NDVI'].min() if 'NDVI' in group.columns else 0\n",
    "#         ndvi_std = group['NDVI'].std() if 'NDVI' in group.columns else 0\n",
    "        \n",
    "#         evi_range = group['EVI'].max() - group['EVI'].min() if 'EVI' in group.columns else 0\n",
    "#         evi_std = group['EVI'].std() if 'EVI' in group.columns else 0\n",
    "        \n",
    "#         b8_range = group['B8_mean'].max() - group['B8_mean'].min()\n",
    "#         b8_std = group['B8_mean'].std()\n",
    "        \n",
    "#         b4_range = group['B4_mean'].max() - group['B4_mean'].min()\n",
    "#         b4_std = group['B4_mean'].std()\n",
    "        \n",
    "#         # Calculate trend (slope) of NDVI over time\n",
    "#         ndvi_trend = 0\n",
    "#         if month_count > 1 and 'NDVI' in group.columns and 'month_num' in group.columns:\n",
    "#             # Simple linear regression slope calculation\n",
    "#             x = group['month_num'].values\n",
    "#             y = group['NDVI'].values\n",
    "#             slope = np.polyfit(x, y, 1)[0]\n",
    "#             ndvi_trend = slope\n",
    "        \n",
    "#         # Extend the lists with the calculated values (repeated for each row in the group)\n",
    "#         for _ in range(len(group)):\n",
    "#             new_features['NDVI_range'].append(ndvi_range)\n",
    "#             new_features['NDVI_std'].append(ndvi_std)\n",
    "#             new_features['NDVI_trend'].append(ndvi_trend)\n",
    "#             new_features['EVI_range'].append(evi_range)\n",
    "#             new_features['EVI_std'].append(evi_std)\n",
    "#             new_features['B8_range'].append(b8_range)\n",
    "#             new_features['B8_std'].append(b8_std)\n",
    "#             new_features['B4_range'].append(b4_range)\n",
    "#             new_features['B4_std'].append(b4_std)\n",
    "#             new_features['month_count'].append(month_count)\n",
    "    \n",
    "#     # Add the new features to the dataframe\n",
    "#     for feature, values in new_features.items():\n",
    "#         df[feature] = values\n",
    "    \n",
    "#     # Calculate additional temporal features\n",
    "    \n",
    "#     # Deviation from base_id average for key features\n",
    "#     for feature in ['NDVI', 'EVI', 'B4_mean', 'B8_mean', 'B11_mean']:\n",
    "#         if feature in df.columns:\n",
    "#             # Calculate mean for each base_id\n",
    "#             feature_mean = df.groupby('base_id')[feature].transform('mean')\n",
    "#             # Calculate deviation from mean\n",
    "#             df[f'{feature}_dev_from_mean'] = df[feature] - feature_mean\n",
    "    \n",
    "#     # Relative position in the year's cycle for each observation\n",
    "#     if 'month_num' in df.columns:\n",
    "#         df['relative_month_position'] = (df['month_num'] - df.groupby('base_id')['month_num'].transform('min')) / \\\n",
    "#                                       (df.groupby('base_id')['month_num'].transform('max') - \n",
    "#                                        df.groupby('base_id')['month_num'].transform('min') + 1)\n",
    "    \n",
    "#     # Calculate percentile rank of each observation within its base_id group\n",
    "#     for feature in ['NDVI', 'EVI', 'B4', 'B8']:\n",
    "#         if feature in df.columns:\n",
    "#             df[f'{feature}_percentile'] = df.groupby('base_id')[feature].transform(\n",
    "#                 lambda x: (x.rank(method='min') - 1) / (len(x) - 1) if len(x) > 1 else 0.5\n",
    "#             )\n",
    "    \n",
    "#     return df\n",
    "    \n",
    "# train_df = create_temporal_features(train_df)\n",
    "# test_df = create_temporal_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "006e131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_crop_specific_features(df):\n",
    "    \"\"\"Add features specifically designed for crop type discrimination\"\"\"\n",
    "    \n",
    "    # Crop-specific indices\n",
    "    \n",
    "    # TCARI (Transformed Chlorophyll Absorption Ratio Index)\n",
    "    # Good for chlorophyll content estimation\n",
    "    df['TCARI'] = 3 * ((df['B5_mean'] - df['B4_mean']) - 0.2 * (df['B5_mean'] - df['B3_mean']) * (df['B5_mean'] / df['B4_mean']))\n",
    "    \n",
    "    # MCARI2 (Modified Chlorophyll Absorption Ratio Index Improved)\n",
    "    # Better for LAI estimation\n",
    "    df['MCARI2'] = 1.5 * (2.5 * (df['B8_mean'] - df['B4_mean']) - 1.3 * (df['B8_mean'] - df['B3_mean'])) / np.sqrt((2 * df['B8_mean'] + 1)**2 - (6 * df['B8_mean'] - 5 * np.sqrt(df['B4_mean'])) - 0.5)\n",
    "    \n",
    "    # WDRVI (Wide Dynamic Range Vegetation Index)\n",
    "    # Better for high biomass conditions\n",
    "    a = 0.1  # weighting coefficient\n",
    "    df['WDRVI'] = (a * df['B8_mean'] - df['B4_mean']) / (a * df['B8_mean'] + df['B4_mean'])\n",
    "    \n",
    "    # MTVI2 (Modified Triangular Vegetation Index 2)\n",
    "    # Good for LAI estimation\n",
    "    df['MTVI2'] = 1.5 * (1.2 * (df['B8_mean'] - df['B3_mean']) - 2.5 * (df['B4_mean'] - df['B3_mean'])) / np.sqrt((2 * df['B8_mean'] + 1)**2 - (6 * df['B8_mean'] - 5 * np.sqrt(df['B4_mean'])) - 0.5)\n",
    "    \n",
    "    # Canopy Chlorophyll Content Index\n",
    "    df['CCCI'] = ((df['B8_mean'] - df['B5_mean']) / (df['B8_mean'] + df['B5_mean'])) / ((df['B8_mean'] - df['B4_mean']) / (df['B8_mean'] + df['B4_mean']))\n",
    "    \n",
    "    # Specific band combinations for crop discrimination\n",
    "    df['B8_B11_B4'] = df['B8_mean'] / (df['B11_mean'] * df['B4_mean'])\n",
    "    df['B8_B11_B2'] = df['B8_mean'] / (df['B11_mean'] * df['B2_mean'])\n",
    "    \n",
    "    # Texture homogeneity approximation\n",
    "    df['texture_homogeneity'] = 1 / (1 + df['var_vis_ratio'] + df['var_nir_ratio'] + df['var_swir_ratio'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "train_df = add_crop_specific_features(train_df)\n",
    "test_df = add_crop_specific_features(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6b0a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle potential NaN values from division operations\n",
    "train_df = train_df.replace([np.inf, -np.inf], np.nan)\n",
    "test_df = test_df.replace([np.inf, -np.inf], np.nan)\n",
    "train_df = train_df.fillna(0)\n",
    "test_df = test_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fe4b55c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98456ead",
   "metadata": {},
   "source": [
    "### Save the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "445ee415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "809da380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ID_058797' in test_df['submission_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93053b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Save the data\n",
    "train_df.to_csv(os.path.join(DATA_PATH, \"train_df.csv\"), index=False)\n",
    "test_df.to_csv(os.path.join(DATA_PATH, \"test_df.csv\"), index=False)\n",
    "print(\"Data saved successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zindi_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
