{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8076a84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "import datetime\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95547a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "DATA_PATH = 'datasets'\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'train_df.csv'))\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, 'test_df.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d12151c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>month</th>\n",
       "      <th>B1_mean</th>\n",
       "      <th>B1_std</th>\n",
       "      <th>B1_min</th>\n",
       "      <th>B1_max</th>\n",
       "      <th>B1_median</th>\n",
       "      <th>B2_mean</th>\n",
       "      <th>B2_std</th>\n",
       "      <th>B2_min</th>\n",
       "      <th>...</th>\n",
       "      <th>vis_swir_ratio</th>\n",
       "      <th>LAI_approx</th>\n",
       "      <th>TCARI</th>\n",
       "      <th>MCARI2</th>\n",
       "      <th>WDRVI</th>\n",
       "      <th>MTVI2</th>\n",
       "      <th>CCCI</th>\n",
       "      <th>B8_B11_B4</th>\n",
       "      <th>B8_B11_B2</th>\n",
       "      <th>texture_homogeneity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_ZUfp59_Jan</td>\n",
       "      <td>Jan</td>\n",
       "      <td>3119.697</td>\n",
       "      <td>593.1587</td>\n",
       "      <td>2584.0</td>\n",
       "      <td>4595.0</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>2963.4856</td>\n",
       "      <td>760.8518</td>\n",
       "      <td>2267.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857228</td>\n",
       "      <td>-13.389297</td>\n",
       "      <td>525.596848</td>\n",
       "      <td>0.358802</td>\n",
       "      <td>-0.724257</td>\n",
       "      <td>0.358802</td>\n",
       "      <td>0.858681</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_KfCbOO_Jan</td>\n",
       "      <td>Jan</td>\n",
       "      <td>4412.240</td>\n",
       "      <td>496.0062</td>\n",
       "      <td>3406.0</td>\n",
       "      <td>5444.0</td>\n",
       "      <td>4367.0</td>\n",
       "      <td>4380.4610</td>\n",
       "      <td>642.4509</td>\n",
       "      <td>2979.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.941388</td>\n",
       "      <td>-16.083742</td>\n",
       "      <td>-302.758152</td>\n",
       "      <td>0.057786</td>\n",
       "      <td>-0.797462</td>\n",
       "      <td>0.057786</td>\n",
       "      <td>1.128000</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 160 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID month   B1_mean    B1_std  B1_min  B1_max  B1_median  \\\n",
       "0  ID_ZUfp59_Jan   Jan  3119.697  593.1587  2584.0  4595.0     2810.0   \n",
       "1  ID_KfCbOO_Jan   Jan  4412.240  496.0062  3406.0  5444.0     4367.0   \n",
       "\n",
       "     B2_mean    B2_std  B2_min  ...  vis_swir_ratio  LAI_approx       TCARI  \\\n",
       "0  2963.4856  760.8518  2267.0  ...        0.857228  -13.389297  525.596848   \n",
       "1  4380.4610  642.4509  2979.0  ...        0.941388  -16.083742 -302.758152   \n",
       "\n",
       "     MCARI2     WDRVI     MTVI2      CCCI  B8_B11_B4  B8_B11_B2  \\\n",
       "0  0.358802 -0.724257  0.358802  0.858681   0.000414   0.000388   \n",
       "1  0.057786 -0.797462  0.057786  1.128000   0.000218   0.000227   \n",
       "\n",
       "   texture_homogeneity  \n",
       "0             0.000374  \n",
       "1             0.000395  \n",
       "\n",
       "[2 rows x 160 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fcd6dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (7433, 160)\n",
      "Test shape: (2201, 157)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "885de832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Crop', 'Crop_encoded', 'class'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print cols  in train df and not in test_df\n",
    "\n",
    "train_cols = set(train_df.columns)\n",
    "test_cols = set(test_df.columns)\n",
    "\n",
    "cols_in_train_not_in_test = train_cols - test_cols\n",
    "cols_in_train_not_in_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe37c16",
   "metadata": {},
   "source": [
    "### Model Training and Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e17e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of features: 153\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Features and labels\n",
    "feature_cols = [col for col in train_df.columns if col not in ['ID', 'month', 'Crop', 'Crop_encoded', 'class', 'base_id', 'submission_id', '']]\n",
    "print(f\"\\nNumber of features: {len(feature_cols)}\")\n",
    "\n",
    "\n",
    "def handle_outliers(df, cols, method='clip', threshold=3):\n",
    "    \"\"\"Handle outliers in the dataset\"\"\"\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    for col in cols:\n",
    "        if method == 'clip':\n",
    "            # Clip values beyond 3 standard deviations\n",
    "            mean, std = df[col].mean(), df[col].std()\n",
    "            df_processed[col] = df[col].clip(lower=mean - threshold * std, \n",
    "                                            upper=mean + threshold * std)\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "# Apply outlier handling to numerical features\n",
    "train_df = handle_outliers(train_df, feature_cols)\n",
    "test_df = handle_outliers(test_df, feature_cols)\n",
    "\n",
    "X = train_df[feature_cols]\n",
    "y = train_df['Crop_encoded']\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "# Scale features\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "test_scaled = scaler.transform(test_df[feature_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87000361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training with Group K-Fold Cross Validation (grouped by base_id)...\n",
      "\n",
      "Fold 1/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[261]\tval's multi_logloss: 0.302773\n",
      "Fold 1 - Log Loss: 0.3028, F1 (macro): 0.8869\n",
      "\n",
      "Fold 2/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[244]\tval's multi_logloss: 0.322751\n",
      "Fold 2 - Log Loss: 0.3228, F1 (macro): 0.8803\n",
      "\n",
      "Fold 3/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[246]\tval's multi_logloss: 0.366495\n",
      "Fold 3 - Log Loss: 0.3665, F1 (macro): 0.8657\n",
      "\n",
      "Fold 4/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[241]\tval's multi_logloss: 0.34779\n",
      "Fold 4 - Log Loss: 0.3478, F1 (macro): 0.8567\n",
      "\n",
      "Fold 5/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[271]\tval's multi_logloss: 0.328732\n",
      "Fold 5 - Log Loss: 0.3287, F1 (macro): 0.8881\n",
      "\n",
      "Cross-Validation Results:\n",
      "Average Log Loss: 0.3337 ± 0.0218\n",
      "Average F1 (macro): 0.8756 ± 0.0123\n",
      "\n",
      "Best model is from fold 1 with Log Loss: 0.3028\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import log_loss, f1_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Extract base_id from ID column\n",
    "# Assuming train_df has an 'ID' column in format 'ID_baseID_month'\n",
    "train_df['base_id'] = train_df['ID'].str.split('_').str[1]\n",
    "\n",
    "# Best trial parameters from Optuna\n",
    "lgb_params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'metric': 'multi_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 137,\n",
    "    'learning_rate': 0.027697377730760003,\n",
    "    'feature_fraction': 0.7208696427088392,\n",
    "    'bagging_fraction': 0.6569929691949516,\n",
    "    'bagging_freq': 1,\n",
    "    'min_data_in_leaf': 22,\n",
    "    'lambda_l1': 0.015201238267261608,\n",
    "    'lambda_l2': 0.1160134340820291,\n",
    "    'verbose': -1,\n",
    "    'random_state': SEED\n",
    "}\n",
    "\n",
    "# Cross-validation with GroupKFold\n",
    "# This ensures samples from the same base_id stay in the same fold\n",
    "print(\"\\n\\nTraining with Group K-Fold Cross Validation (grouped by base_id)...\")\n",
    "n_folds = 5\n",
    "\n",
    "# Create groups based on base_id\n",
    "groups = train_df['base_id'].values\n",
    "\n",
    "# Initialize GroupKFold\n",
    "gkf = GroupKFold(n_splits=n_folds)\n",
    "\n",
    "# Lists to store metrics\n",
    "cv_scores = []\n",
    "f1_macro_scores = []\n",
    "models = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(X_scaled, y, groups=groups)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_folds}\")\n",
    "\n",
    "    # Get the data for this fold\n",
    "    X_train_fold, X_val_fold = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "    # Create LightGBM datasets\n",
    "    train_data = lgb.Dataset(X_train_fold, label=y_train_fold)\n",
    "    val_data = lgb.Dataset(X_val_fold, label=y_val_fold, reference=train_data)\n",
    "\n",
    "    # Train the model\n",
    "    model = lgb.train(\n",
    "        lgb_params,\n",
    "        train_data,\n",
    "        num_boost_round=500,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=['val'],\n",
    "        callbacks=[lgb.early_stopping(50)]\n",
    "    )\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_proba = model.predict(X_val_fold)\n",
    "    y_pred_class = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    loss = log_loss(y_val_fold, y_pred_proba)\n",
    "    f1_macro = f1_score(y_val_fold, y_pred_class, average='macro')\n",
    "    \n",
    "    # Store metrics\n",
    "    cv_scores.append(loss)\n",
    "    f1_macro_scores.append(f1_macro)\n",
    "    models.append(model)\n",
    "    \n",
    "    # Print fold results\n",
    "    print(f\"Fold {fold+1} - Log Loss: {loss:.4f}, F1 (macro): {f1_macro:.4f}\")\n",
    "\n",
    "# Print average results\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average Log Loss: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n",
    "print(f\"Average F1 (macro): {np.mean(f1_macro_scores):.4f} ± {np.std(f1_macro_scores):.4f}\")\n",
    "\n",
    "# You can use the best model or ensemble all models for final predictions\n",
    "best_model_idx = np.argmin(cv_scores)\n",
    "best_model = models[best_model_idx]\n",
    "print(f\"\\nBest model is from fold {best_model_idx+1} with Log Loss: {cv_scores[best_model_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f9b99d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 11:49:46,043] A new study created in memory with name: no-name-4e3a1e61-9b83-4efd-a27e-a645b8abf9bc\n",
      "[I 2025-06-09 11:52:03,354] Trial 0 finished with value: 0.33696446362962834 and parameters: {'num_leaves': 45, 'learning_rate': 0.010633278321338868, 'feature_fraction': 0.7014105772658538, 'bagging_fraction': 0.5605199660204749, 'bagging_freq': 5, 'min_data_in_leaf': 37, 'lambda_l1': 0.008988026645796258, 'lambda_l2': 0.000920562914488249}. Best is trial 0 with value: 0.33696446362962834.\n",
      "[I 2025-06-09 11:56:20,693] Trial 1 finished with value: 0.34484410894824713 and parameters: {'num_leaves': 111, 'learning_rate': 0.006102829952842516, 'feature_fraction': 0.7687823244514614, 'bagging_fraction': 0.675459963790132, 'bagging_freq': 6, 'min_data_in_leaf': 42, 'lambda_l1': 0.0008067216863158497, 'lambda_l2': 0.0008326490751171683}. Best is trial 0 with value: 0.33696446362962834.\n",
      "[I 2025-06-09 11:56:41,359] Trial 2 finished with value: 0.35059269396503645 and parameters: {'num_leaves': 25, 'learning_rate': 0.15863948836143257, 'feature_fraction': 0.8928890485293874, 'bagging_fraction': 0.8001179357719639, 'bagging_freq': 10, 'min_data_in_leaf': 19, 'lambda_l1': 0.00013063275161184334, 'lambda_l2': 0.005099189751901938}. Best is trial 0 with value: 0.33696446362962834.\n",
      "[I 2025-06-09 12:04:12,423] Trial 3 finished with value: 0.3398313141062545 and parameters: {'num_leaves': 127, 'learning_rate': 0.006233536468991186, 'feature_fraction': 0.8510416408037547, 'bagging_fraction': 0.8366388722190656, 'bagging_freq': 7, 'min_data_in_leaf': 13, 'lambda_l1': 0.04791186620328677, 'lambda_l2': 0.0005482072070071129}. Best is trial 0 with value: 0.33696446362962834.\n",
      "[I 2025-06-09 12:04:49,198] Trial 4 finished with value: 0.33834533255054294 and parameters: {'num_leaves': 30, 'learning_rate': 0.090919146290138, 'feature_fraction': 0.8507331963272515, 'bagging_fraction': 0.8543378117606657, 'bagging_freq': 5, 'min_data_in_leaf': 14, 'lambda_l1': 0.3339422198897952, 'lambda_l2': 0.056792062370749054}. Best is trial 0 with value: 0.33696446362962834.\n",
      "[I 2025-06-09 12:10:08,037] Trial 5 finished with value: 0.43326797931792466 and parameters: {'num_leaves': 67, 'learning_rate': 0.002277413538887112, 'feature_fraction': 0.8915804254501645, 'bagging_fraction': 0.8250738327848208, 'bagging_freq': 2, 'min_data_in_leaf': 15, 'lambda_l1': 0.00611590173840223, 'lambda_l2': 0.006452985688469705}. Best is trial 0 with value: 0.33696446362962834.\n",
      "[I 2025-06-09 12:13:51,916] Trial 6 finished with value: 0.3333125337729902 and parameters: {'num_leaves': 125, 'learning_rate': 0.008136995573947309, 'feature_fraction': 0.6785073838177291, 'bagging_fraction': 0.8546093515439783, 'bagging_freq': 4, 'min_data_in_leaf': 37, 'lambda_l1': 0.0003741302719731339, 'lambda_l2': 0.6368558556062762}. Best is trial 6 with value: 0.3333125337729902.\n",
      "[I 2025-06-09 12:18:26,828] Trial 7 finished with value: 0.4093025642912651 and parameters: {'num_leaves': 117, 'learning_rate': 0.002753161590605941, 'feature_fraction': 0.8411981214174307, 'bagging_fraction': 0.6379615034998185, 'bagging_freq': 2, 'min_data_in_leaf': 21, 'lambda_l1': 0.4263547631530077, 'lambda_l2': 0.00621507356099694}. Best is trial 6 with value: 0.3333125337729902.\n",
      "[I 2025-06-09 12:19:34,008] Trial 8 finished with value: 0.3362396763839648 and parameters: {'num_leaves': 140, 'learning_rate': 0.035496085887862495, 'feature_fraction': 0.6692511923511785, 'bagging_fraction': 0.6089205178752429, 'bagging_freq': 1, 'min_data_in_leaf': 37, 'lambda_l1': 0.006537064993292077, 'lambda_l2': 0.00012831354186887834}. Best is trial 6 with value: 0.3333125337729902.\n",
      "[I 2025-06-09 12:22:08,192] Trial 9 finished with value: 0.33279625312154065 and parameters: {'num_leaves': 69, 'learning_rate': 0.011998088962953917, 'feature_fraction': 0.516064374156437, 'bagging_fraction': 0.7682387379978911, 'bagging_freq': 3, 'min_data_in_leaf': 33, 'lambda_l1': 0.00016169086440963125, 'lambda_l2': 0.02683980754598926}. Best is trial 9 with value: 0.33279625312154065.\n",
      "[I 2025-06-09 12:23:16,886] Trial 10 finished with value: 0.33381885990930527 and parameters: {'num_leaves': 86, 'learning_rate': 0.027607741059914384, 'feature_fraction': 0.5074749011859223, 'bagging_fraction': 0.9945286422659276, 'bagging_freq': 8, 'min_data_in_leaf': 50, 'lambda_l1': 0.0010314215348552888, 'lambda_l2': 0.07323515978392439}. Best is trial 9 with value: 0.33279625312154065.\n",
      "[I 2025-06-09 12:26:45,669] Trial 11 finished with value: 0.5993893675034827 and parameters: {'num_leaves': 90, 'learning_rate': 0.0010543812108263686, 'feature_fraction': 0.5292022050799547, 'bagging_fraction': 0.9445367441447708, 'bagging_freq': 3, 'min_data_in_leaf': 28, 'lambda_l1': 0.00022472621638315837, 'lambda_l2': 0.8700962344375232}. Best is trial 9 with value: 0.33279625312154065.\n",
      "[I 2025-06-09 12:28:19,606] Trial 12 finished with value: 0.3341053519742147 and parameters: {'num_leaves': 62, 'learning_rate': 0.0210149450368352, 'feature_fraction': 0.594203876260651, 'bagging_fraction': 0.7241843780723997, 'bagging_freq': 4, 'min_data_in_leaf': 29, 'lambda_l1': 0.0006664204314555974, 'lambda_l2': 0.6780414474756684}. Best is trial 9 with value: 0.33279625312154065.\n",
      "[I 2025-06-09 12:31:38,323] Trial 13 finished with value: 0.3327491832487902 and parameters: {'num_leaves': 149, 'learning_rate': 0.00958929930553705, 'feature_fraction': 0.6095114107815001, 'bagging_fraction': 0.9103132927771164, 'bagging_freq': 3, 'min_data_in_leaf': 36, 'lambda_l1': 0.00011339521093141172, 'lambda_l2': 0.1310179939097374}. Best is trial 13 with value: 0.3327491832487902.\n",
      "[I 2025-06-09 12:32:22,064] Trial 14 finished with value: 0.33616539190946526 and parameters: {'num_leaves': 150, 'learning_rate': 0.054671790570946614, 'feature_fraction': 0.5883439977531388, 'bagging_fraction': 0.9192819681300061, 'bagging_freq': 1, 'min_data_in_leaf': 45, 'lambda_l1': 0.0021209842361109487, 'lambda_l2': 0.06575492746720528}. Best is trial 13 with value: 0.3327491832487902.\n",
      "[I 2025-06-09 12:35:28,640] Trial 15 finished with value: 0.3362692101448464 and parameters: {'num_leaves': 103, 'learning_rate': 0.013503988235614514, 'feature_fraction': 0.9926050143439398, 'bagging_fraction': 0.7436631776140978, 'bagging_freq': 3, 'min_data_in_leaf': 26, 'lambda_l1': 0.00011765267879554074, 'lambda_l2': 0.0282655420064653}. Best is trial 13 with value: 0.3327491832487902.\n",
      "[I 2025-06-09 12:37:38,154] Trial 16 finished with value: 0.41534238798902157 and parameters: {'num_leaves': 68, 'learning_rate': 0.003355600940729326, 'feature_fraction': 0.5814438900950104, 'bagging_fraction': 0.5117854313616261, 'bagging_freq': 3, 'min_data_in_leaf': 34, 'lambda_l1': 0.036696843257485394, 'lambda_l2': 0.22377065020345754}. Best is trial 13 with value: 0.3327491832487902.\n",
      "[I 2025-06-09 12:39:30,556] Trial 17 finished with value: 0.333473902463942 and parameters: {'num_leaves': 97, 'learning_rate': 0.016622989416218873, 'feature_fraction': 0.6241054650655058, 'bagging_fraction': 0.9111085362195425, 'bagging_freq': 4, 'min_data_in_leaf': 43, 'lambda_l1': 0.002577772700971097, 'lambda_l2': 0.019910615841521335}. Best is trial 13 with value: 0.3327491832487902.\n",
      "[I 2025-06-09 12:40:10,795] Trial 18 finished with value: 0.3398258311753094 and parameters: {'num_leaves': 52, 'learning_rate': 0.052938885200299456, 'feature_fraction': 0.5331573818226673, 'bagging_fraction': 0.7753846952459954, 'bagging_freq': 6, 'min_data_in_leaf': 32, 'lambda_l1': 0.039179882911663536, 'lambda_l2': 0.22424620260531533}. Best is trial 13 with value: 0.3327491832487902.\n",
      "[I 2025-06-09 12:44:13,490] Trial 19 finished with value: 0.34920651710113165 and parameters: {'num_leaves': 83, 'learning_rate': 0.00475719363228163, 'feature_fraction': 0.7462192555477227, 'bagging_fraction': 0.6890498843511373, 'bagging_freq': 2, 'min_data_in_leaf': 24, 'lambda_l1': 0.00010071893441453049, 'lambda_l2': 0.16433608805894828}. Best is trial 13 with value: 0.3327491832487902.\n",
      "[I 2025-06-09 12:48:00,335] Trial 20 finished with value: 0.5254227091743839 and parameters: {'num_leaves': 75, 'learning_rate': 0.001462063643998129, 'feature_fraction': 0.6400559929752729, 'bagging_fraction': 0.983051181752068, 'bagging_freq': 10, 'min_data_in_leaf': 34, 'lambda_l1': 0.0003226826556299305, 'lambda_l2': 0.0022733329513294465}. Best is trial 13 with value: 0.3327491832487902.\n",
      "[I 2025-06-09 12:51:22,793] Trial 21 finished with value: 0.33104975518743196 and parameters: {'num_leaves': 133, 'learning_rate': 0.009408604369690496, 'feature_fraction': 0.6998742751116689, 'bagging_fraction': 0.8764511059090994, 'bagging_freq': 4, 'min_data_in_leaf': 39, 'lambda_l1': 0.00036956339429352177, 'lambda_l2': 0.37985921649621784}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 12:53:58,476] Trial 22 finished with value: 0.3323376384559975 and parameters: {'num_leaves': 150, 'learning_rate': 0.011171599040602952, 'feature_fraction': 0.5508231852527139, 'bagging_fraction': 0.889256642930377, 'bagging_freq': 4, 'min_data_in_leaf': 40, 'lambda_l1': 0.00032493559128547305, 'lambda_l2': 0.019411997565193618}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 12:57:20,223] Trial 23 finished with value: 0.3318112520441936 and parameters: {'num_leaves': 148, 'learning_rate': 0.010340992233818016, 'feature_fraction': 0.7179509233160236, 'bagging_fraction': 0.8930128521334117, 'bagging_freq': 5, 'min_data_in_leaf': 41, 'lambda_l1': 0.001714693767466263, 'lambda_l2': 0.13711274108617924}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 12:58:40,485] Trial 24 finished with value: 0.33315815969015344 and parameters: {'num_leaves': 134, 'learning_rate': 0.026730765981324907, 'feature_fraction': 0.7377970142316939, 'bagging_fraction': 0.8767733636928124, 'bagging_freq': 7, 'min_data_in_leaf': 41, 'lambda_l1': 0.002320982285263987, 'lambda_l2': 0.3908615573817988}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 13:02:16,661] Trial 25 finished with value: 0.3610888210881546 and parameters: {'num_leaves': 141, 'learning_rate': 0.004422285255500519, 'feature_fraction': 0.7241306875707699, 'bagging_fraction': 0.9476538705442566, 'bagging_freq': 5, 'min_data_in_leaf': 48, 'lambda_l1': 0.000522309330404936, 'lambda_l2': 0.01506949767308676}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 13:04:40,698] Trial 26 finished with value: 0.33303195266761315 and parameters: {'num_leaves': 130, 'learning_rate': 0.017073010798103472, 'feature_fraction': 0.7948331479581239, 'bagging_fraction': 0.8950546229515184, 'bagging_freq': 6, 'min_data_in_leaf': 40, 'lambda_l1': 0.0012430224983441067, 'lambda_l2': 0.3729487417166154}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 13:08:48,128] Trial 27 finished with value: 0.33609939217978313 and parameters: {'num_leaves': 117, 'learning_rate': 0.007104610683155607, 'feature_fraction': 0.791110509291598, 'bagging_fraction': 0.8192458163972546, 'bagging_freq': 4, 'min_data_in_leaf': 46, 'lambda_l1': 0.003913951929757165, 'lambda_l2': 0.09706131329059471}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 13:09:36,508] Trial 28 finished with value: 0.3364464566363199 and parameters: {'num_leaves': 141, 'learning_rate': 0.04120797175293331, 'feature_fraction': 0.5490303448436135, 'bagging_fraction': 0.9622089562100518, 'bagging_freq': 8, 'min_data_in_leaf': 40, 'lambda_l1': 0.0013984341791743492, 'lambda_l2': 0.04125937415188752}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 13:12:21,829] Trial 29 finished with value: 0.33304670057260677 and parameters: {'num_leaves': 148, 'learning_rate': 0.01219618434056066, 'feature_fraction': 0.6968198377994793, 'bagging_fraction': 0.8747421690206816, 'bagging_freq': 5, 'min_data_in_leaf': 45, 'lambda_l1': 0.012397841895859012, 'lambda_l2': 0.002465682592530114}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 13:16:31,725] Trial 30 finished with value: 0.3571997429267219 and parameters: {'num_leaves': 120, 'learning_rate': 0.004300941295100862, 'feature_fraction': 0.6476589771989536, 'bagging_fraction': 0.8828170508373835, 'bagging_freq': 4, 'min_data_in_leaf': 38, 'lambda_l1': 0.0003475504330659554, 'lambda_l2': 0.011485940467653923}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 13:19:46,983] Trial 31 finished with value: 0.3328196222553327 and parameters: {'num_leaves': 150, 'learning_rate': 0.00945180095472067, 'feature_fraction': 0.6125963130397294, 'bagging_fraction': 0.9256308488657604, 'bagging_freq': 3, 'min_data_in_leaf': 35, 'lambda_l1': 0.00022984944633507257, 'lambda_l2': 0.1090374405727146}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 13:22:54,095] Trial 32 finished with value: 0.3322692207936135 and parameters: {'num_leaves': 137, 'learning_rate': 0.009154669234458788, 'feature_fraction': 0.5706669795483761, 'bagging_fraction': 0.7949585860935988, 'bagging_freq': 5, 'min_data_in_leaf': 43, 'lambda_l1': 0.000561070102799722, 'lambda_l2': 0.1605758376616944}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 13:24:20,801] Trial 33 finished with value: 0.3332457224309624 and parameters: {'num_leaves': 136, 'learning_rate': 0.020432846680252074, 'feature_fraction': 0.5601785629945579, 'bagging_fraction': 0.7987129543111792, 'bagging_freq': 5, 'min_data_in_leaf': 43, 'lambda_l1': 0.0006320028546295876, 'lambda_l2': 0.3385049585940779}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 13:27:21,136] Trial 34 finished with value: 0.34863932976510215 and parameters: {'num_leaves': 105, 'learning_rate': 0.005778994490604444, 'feature_fraction': 0.7105785939285044, 'bagging_fraction': 0.7965467771327139, 'bagging_freq': 6, 'min_data_in_leaf': 49, 'lambda_l1': 0.0008544296690051577, 'lambda_l2': 0.22797291557932392}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 13:32:18,828] Trial 35 finished with value: 0.3318496696942947 and parameters: {'num_leaves': 128, 'learning_rate': 0.007747690042215182, 'feature_fraction': 0.6765434299977029, 'bagging_fraction': 0.8439808413733033, 'bagging_freq': 7, 'min_data_in_leaf': 39, 'lambda_l1': 0.00045776811143868694, 'lambda_l2': 0.04327019311473377}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 13:36:17,036] Trial 36 finished with value: 0.3472936494958371 and parameters: {'num_leaves': 125, 'learning_rate': 0.005744061141209556, 'feature_fraction': 0.7780289532636626, 'bagging_fraction': 0.8414944129362025, 'bagging_freq': 7, 'min_data_in_leaf': 47, 'lambda_l1': 0.01715889336760147, 'lambda_l2': 0.47329345208521606}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 13:41:07,500] Trial 37 finished with value: 0.33705354284253836 and parameters: {'num_leaves': 113, 'learning_rate': 0.0077966685893598705, 'feature_fraction': 0.6706953488025355, 'bagging_fraction': 0.7305141093416228, 'bagging_freq': 8, 'min_data_in_leaf': 10, 'lambda_l1': 0.1431216120261499, 'lambda_l2': 0.04312702822680897}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 13:45:55,831] Trial 38 finished with value: 0.4612712335800844 and parameters: {'num_leaves': 134, 'learning_rate': 0.0019447229722080388, 'feature_fraction': 0.8270548004961079, 'bagging_fraction': 0.8563779653352348, 'bagging_freq': 9, 'min_data_in_leaf': 31, 'lambda_l1': 0.004296802780924011, 'lambda_l2': 0.16817449672127777}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 13:49:04,466] Trial 39 finished with value: 0.4055174936258178 and parameters: {'num_leaves': 126, 'learning_rate': 0.0032379204889464194, 'feature_fraction': 0.7545382273482748, 'bagging_fraction': 0.7045132765944537, 'bagging_freq': 7, 'min_data_in_leaf': 42, 'lambda_l1': 0.0015750761450299515, 'lambda_l2': 0.08456707469666418}. Best is trial 21 with value: 0.33104975518743196.\n",
      "[I 2025-06-09 13:52:58,392] Trial 40 finished with value: 0.3339060648893143 and parameters: {'num_leaves': 110, 'learning_rate': 0.006759043677151761, 'feature_fraction': 0.6505851647936955, 'bagging_fraction': 0.8218334934118628, 'bagging_freq': 5, 'min_data_in_leaf': 38, 'lambda_l1': 0.0004615343434220341, 'lambda_l2': 0.04826082673071967}. Best is trial 21 with value: 0.33104975518743196.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating best model with GroupKFold...\n",
      "\n",
      "Fold 1/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[914]\tval's multi_logloss: 0.305365\n",
      "\n",
      "Fold 2/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[832]\tval's multi_logloss: 0.320309\n",
      "\n",
      "Fold 3/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[778]\tval's multi_logloss: 0.357216\n",
      "\n",
      "Fold 4/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[853]\tval's multi_logloss: 0.3458\n",
      "\n",
      "Fold 5/5\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[884]\tval's multi_logloss: 0.326559\n",
      "\n",
      "✅ Final Evaluation\n",
      "Best Fold: 1\n",
      "Best Log Loss: 0.3054\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Create base_id groupings\n",
    "train_df['base_id'] = train_df['ID'].str.split('_').str[1]\n",
    "groups = train_df['base_id'].values\n",
    "\n",
    "# Define Optuna objective function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 3,\n",
    "        'metric': 'multi_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.2, log=True),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.5, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 10, 50),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-4, 1.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-4, 1.0, log=True),\n",
    "        'verbose': -1,\n",
    "        'random_state': SEED,\n",
    "    }\n",
    "\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    log_losses, f1_macros = [], []\n",
    "\n",
    "    for train_idx, val_idx in gkf.split(X_scaled, y, groups=groups):\n",
    "        X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            num_boost_round=1000,\n",
    "            valid_sets=[val_data],\n",
    "            callbacks=[lgb.early_stopping(50, verbose=False)]\n",
    "        )\n",
    "\n",
    "        y_pred_proba = model.predict(X_val)\n",
    "        y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "        log_losses.append(log_loss(y_val, y_pred_proba))\n",
    "        f1_macros.append(f1_score(y_val, y_pred, average='macro'))\n",
    "\n",
    "    return np.mean(log_losses)\n",
    "\n",
    "# Run Optuna with 2-hour timeout\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, timeout=7200)  # 7200 seconds = 2 hours\n",
    "\n",
    "# Best parameters\n",
    "best_params = study.best_params\n",
    "best_params.update({\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'metric': 'multi_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbose': -1,\n",
    "    'random_state': SEED\n",
    "})\n",
    "\n",
    "# Final evaluation with best params\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "log_losses, f1_macros, models = [], [], []\n",
    "\n",
    "print(\"\\nEvaluating best model with GroupKFold...\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(X_scaled, y, groups=groups)):\n",
    "    print(f\"\\nFold {fold+1}/5\")\n",
    "    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    val_data = lgb.Dataset(X_val, label=y_val)\n",
    "\n",
    "    model = lgb.train(\n",
    "        best_params,\n",
    "        train_data,\n",
    "        num_boost_round=1000,\n",
    "        valid_sets=[val_data],\n",
    "        valid_names=['val'],\n",
    "        callbacks=[lgb.early_stopping(50)]\n",
    "    )\n",
    "\n",
    "    y_pred_proba = model.predict(X_val)\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "    log_losses.append(log_loss(y_val, y_pred_proba))\n",
    "    f1_macros.append(f1_score(y_val, y_pred, average='macro'))\n",
    "    models.append(model)\n",
    "\n",
    "# Best fold\n",
    "best_fold_idx = int(np.argmin(log_losses))\n",
    "best_model = models[best_fold_idx]\n",
    "\n",
    "# Final report\n",
    "print(\"\\n✅ Final Evaluation\")\n",
    "print(f\"Best Fold: {best_fold_idx+1}\")\n",
    "print(f\"Best Log Loss: {log_losses[best_fold_idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d833861",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0997feee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Log Loss for Best Model (Fold 1): 0.3054\n",
      "\n",
      "F1 Score (macro) for Best Model (Fold 1):  0.8811\n",
      "\n",
      "Confusion Matrix:\n",
      "[[398   9   9]\n",
      " [  9 420  89]\n",
      " [  2  68 479]]\n",
      "\n",
      "Classification Report for Best Model (Fold 1):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Cocoa       0.97      0.96      0.96       416\n",
      "        Palm       0.85      0.81      0.83       518\n",
      "      Rubber       0.83      0.87      0.85       549\n",
      "\n",
      "    accuracy                           0.87      1483\n",
      "   macro avg       0.88      0.88      0.88      1483\n",
      "weighted avg       0.88      0.87      0.87      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predictions from the best model\n",
    "best_fold_idx = np.argmin(cv_scores)\n",
    "best_model = models[best_fold_idx]\n",
    "\n",
    "# Get the validation data from the best fold\n",
    "# We need to recreate the GroupKFold split to get the validation indices\n",
    "gkf_list = list(gkf.split(X_scaled, y, groups=groups))\n",
    "_, val_indices = gkf_list[best_fold_idx]\n",
    "X_val_best = X_scaled[val_indices]\n",
    "y_val_best = y[val_indices]\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = best_model.predict(X_val_best)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_val_best, y_pred)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Cocoa', 'Palm', 'Rubber']\n",
    "\n",
    "# Combined plots\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Confusion matrix plot\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix for Best Model (Fold {best_fold_idx+1})')\n",
    "\n",
    "# Normalized confusion matrix plot\n",
    "plt.subplot(1, 2, 2)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues', cbar=False, xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Normalized Confusion Matrix for Best Model (Fold {best_fold_idx+1})')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the score\n",
    "print(f\"\\nLog Loss for Best Model (Fold {best_fold_idx+1}): {log_loss(y_val_best, y_pred_proba):.4f}\")\n",
    "print(f\"\\nF1 Score (macro) for Best Model (Fold {best_fold_idx+1}): {f1_score(y_val_best, y_pred, average='macro'): .4f}\")\n",
    "\n",
    "# Print classification metrics for the best model\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nClassification Report for Best Model (Fold {best_fold_idx+1}):\")\n",
    "print(classification_report(y_val_best, y_pred, target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1da150f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Feature importance\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m feature_cols = \u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\n\u001b[32m      3\u001b[39m plt.figure(figsize=(\u001b[32m14\u001b[39m, \u001b[32m10\u001b[39m))\n\u001b[32m      4\u001b[39m feature_importance = pd.DataFrame({\n\u001b[32m      5\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mFeature\u001b[39m\u001b[33m'\u001b[39m: feature_cols,\n\u001b[32m      6\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mImportance\u001b[39m\u001b[33m'\u001b[39m: model.feature_importance()\n\u001b[32m      7\u001b[39m })\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "feature_cols = X_train.columns\n",
    "plt.figure(figsize=(14, 10))\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': model.feature_importance()\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "top_features = feature_importance.head(25)\n",
    "sns.barplot(x='Importance', y='Feature', data=top_features)\n",
    "plt.title('Top 25 Feature Importances')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3609ab46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training with Group K-Fold Cross Validation (grouped by base_id)...\n",
      "\n",
      "Fold 1/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 35\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m     34\u001b[39m model = GradientBoostingClassifier(**gb_params)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[32m     38\u001b[39m y_pred_proba = model.predict_proba(X_val_fold)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\janen\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\janen\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:787\u001b[39m, in \u001b[36mBaseGradientBoosting.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, monitor)\u001b[39m\n\u001b[32m    784\u001b[39m     \u001b[38;5;28mself\u001b[39m._resize_state()\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m n_stages = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_stages != \u001b[38;5;28mself\u001b[39m.estimators_.shape[\u001b[32m0\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\janen\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:883\u001b[39m, in \u001b[36mBaseGradientBoosting._fit_stages\u001b[39m\u001b[34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[39m\n\u001b[32m    876\u001b[39m         initial_loss = factor * \u001b[38;5;28mself\u001b[39m._loss(\n\u001b[32m    877\u001b[39m             y_true=y_oob_masked,\n\u001b[32m    878\u001b[39m             raw_prediction=raw_predictions[~sample_mask],\n\u001b[32m    879\u001b[39m             sample_weight=sample_weight_oob_masked,\n\u001b[32m    880\u001b[39m         )\n\u001b[32m    882\u001b[39m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m883\u001b[39m raw_predictions = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[32m    896\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\janen\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:489\u001b[39m, in \u001b[36mBaseGradientBoosting._fit_stage\u001b[39m\u001b[34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[39m\n\u001b[32m    486\u001b[39m     sample_weight = sample_weight * sample_mask.astype(np.float64)\n\u001b[32m    488\u001b[39m X = X_csc \u001b[38;5;28;01mif\u001b[39;00m X_csc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_g_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[32m    494\u001b[39m X_for_tree_update = X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\janen\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\janen\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1404\u001b[39m, in \u001b[36mDecisionTreeRegressor.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input)\u001b[39m\n\u001b[32m   1374\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1375\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, check_input=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m   1376\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[32m   1377\u001b[39m \n\u001b[32m   1378\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1401\u001b[39m \u001b[33;03m        Fitted estimator.\u001b[39;00m\n\u001b[32m   1402\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1404\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1410\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\janen\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    462\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    463\u001b[39m         splitter,\n\u001b[32m    464\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_classes_ = \u001b[38;5;28mself\u001b[39m.n_classes_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Extract base_id from ID column\n",
    "train_df['base_id'] = train_df['ID'].str.split('_').str[1]\n",
    "\n",
    "# Gradient Boosting parameters (you can tune these further)\n",
    "gb_params = {'n_estimators': 333, 'learning_rate': 0.29728232981278574, \n",
    "             'max_depth': 9,'min_samples_split': 8,'min_samples_leaf': 5, \n",
    "             'subsample': 0.5822537141129174, 'max_features': None,\n",
    "             'random_state': SEED\n",
    "}\n",
    "\n",
    "print(\"\\n\\nTraining with Group K-Fold Cross Validation (grouped by base_id)...\")\n",
    "n_folds = 5\n",
    "groups = train_df['base_id'].values\n",
    "\n",
    "gkf = GroupKFold(n_splits=n_folds)\n",
    "\n",
    "cv_scores = []\n",
    "f1_macro_scores = []\n",
    "models = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(gkf.split(X_scaled, y, groups=groups)):\n",
    "    print(f\"\\nFold {fold + 1}/{n_folds}\")\n",
    "\n",
    "    # Get the data for this fold\n",
    "    X_train_fold, X_val_fold = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "    # Train the model\n",
    "    model = GradientBoostingClassifier(**gb_params)\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred_proba = model.predict_proba(X_val_fold)\n",
    "    y_pred_class = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    loss = log_loss(y_val_fold, y_pred_proba)\n",
    "    f1_macro = f1_score(y_val_fold, y_pred_class, average='macro')\n",
    "\n",
    "    # Store metrics\n",
    "    cv_scores.append(loss)\n",
    "    f1_macro_scores.append(f1_macro)\n",
    "    models.append(model)\n",
    "\n",
    "    print(f\"Fold {fold+1} - Log Loss: {loss:.4f}, F1 (macro): {f1_macro:.4f}\")\n",
    "\n",
    "# Print average results\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Average Log Loss: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n",
    "print(f\"Average F1 (macro): {np.mean(f1_macro_scores):.4f} ± {np.std(f1_macro_scores):.4f}\")\n",
    "\n",
    "# Identify the best model\n",
    "best_model_idx = np.argmin(cv_scores)\n",
    "best_model = models[best_model_idx]\n",
    "print(f\"\\nBest model is from fold {best_model_idx+1} with Log Loss: {cv_scores[best_model_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2922f651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Log Loss for Best Model (Fold 1): 0.7494\n",
      "F1 Score (macro) for Best Model (Fold 1):  0.8912\n",
      "\n",
      "Confusion Matrix:\n",
      "[[400  10   6]\n",
      " [  8 429  81]\n",
      " [  3  62 484]]\n",
      "\n",
      "Classification Report for Best Model (Fold 1):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Cocoa       0.97      0.96      0.97       416\n",
      "        Palm       0.86      0.83      0.84       518\n",
      "      Rubber       0.85      0.88      0.86       549\n",
      "\n",
      "    accuracy                           0.89      1483\n",
      "   macro avg       0.89      0.89      0.89      1483\n",
      "weighted avg       0.89      0.89      0.89      1483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get predictions from the best model\n",
    "best_fold_idx = np.argmin(cv_scores)\n",
    "best_model = models[best_fold_idx]\n",
    "\n",
    "# Recreate the GroupKFold split to get validation indices\n",
    "gkf_list = list(gkf.split(X_scaled, y, groups=groups))\n",
    "_, val_indices = gkf_list[best_fold_idx]\n",
    "X_val_best = X_scaled[val_indices]\n",
    "y_val_best = y[val_indices]\n",
    "\n",
    "# Make predictions\n",
    "y_pred_proba = best_model.predict_proba(X_val_best)\n",
    "y_pred = best_model.predict(X_val_best)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_val_best, y_pred)\n",
    "\n",
    "# Define class names\n",
    "class_names = ['Cocoa', 'Palm', 'Rubber']\n",
    "\n",
    "# Combined plots\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Confusion matrix plot\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix for Best Model (Fold {best_fold_idx+1})')\n",
    "\n",
    "# Normalized confusion matrix plot\n",
    "plt.subplot(1, 2, 2)\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues', cbar=False, xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Normalized Confusion Matrix for Best Model (Fold {best_fold_idx+1})')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print scores\n",
    "print(f\"\\nLog Loss for Best Model (Fold {best_fold_idx+1}): {log_loss(y_val_best, y_pred_proba):.4f}\")\n",
    "print(f\"F1 Score (macro) for Best Model (Fold {best_fold_idx+1}): {f1_score(y_val_best, y_pred, average='macro'): .4f}\")\n",
    "\n",
    "# Print classification metrics\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(f\"\\nClassification Report for Best Model (Fold {best_fold_idx+1}):\")\n",
    "print(classification_report(y_val_best, y_pred, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2e8585",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-09 14:04:56,091] A new study created in memory with name: no-name-4a912199-4f23-40bf-a84f-2bf34cb48535\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import log_loss, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 30),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'max_features': trial.suggest_float('max_features', 0.3, 1.0),\n",
    "        'random_state': SEED\n",
    "    }\n",
    "\n",
    "    gkf = GroupKFold(n_splits=5)\n",
    "    losses, f1s = [], []\n",
    "\n",
    "    for train_idx, val_idx in gkf.split(X_scaled, y, groups=groups):\n",
    "        X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "        model = GradientBoostingClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_proba = model.predict_proba(X_val)\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        losses.append(log_loss(y_val, y_pred_proba))\n",
    "        f1s.append(f1_score(y_val, y_pred, average='macro'))\n",
    "\n",
    "    return np.mean(losses)  # Optimize for lowest log loss\n",
    "\n",
    "# Run Optuna with 2-hour timeout (7200 seconds)\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(\n",
    "    objective,\n",
    "    timeout=7200,\n",
    "    callbacks=[optuna.study.MaxTrialsCallback(100, states=(optuna.trial.TrialState.COMPLETE,))]\n",
    ")\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = study.best_params\n",
    "\n",
    "# Re-evaluate best model using GroupKFold CV\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "log_losses, f1_macros = [], []\n",
    "\n",
    "for train_idx, val_idx in gkf.split(X_scaled, y, groups=groups):\n",
    "    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "    model = GradientBoostingClassifier(**best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = model.predict_proba(X_val)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    log_losses.append(log_loss(y_val, y_pred_proba))\n",
    "    f1_macros.append(f1_score(y_val, y_pred, average='macro'))\n",
    "\n",
    "# Summary output\n",
    "print(\"\\n✅ Final Model Summary\")\n",
    "print(\"Model Name: GradientBoostingClassifier\")\n",
    "print(f\"Best Log Loss (avg across folds): {np.mean(log_losses):.4f}\")\n",
    "print(f\"Best F1 Macro (avg across folds): {np.mean(f1_macros):.4f}\")\n",
    "print(\"\\nBest Hyperparameters:\")\n",
    "for key, val in best_params.items():\n",
    "    print(f\"{key}: {val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fdfb47",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee96783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# import lightgbm as lgb\n",
    "# import numpy as np\n",
    "# from sklearn.metrics import log_loss, f1_score\n",
    "# from sklearn.model_selection import GroupKFold\n",
    "\n",
    "# def objective(trial):\n",
    "#     # First determine boosting type\n",
    "#     boosting_type = trial.suggest_categorical('boosting_type', ['gbdt', 'dart', 'goss'])\n",
    "    \n",
    "#     # Base parameters\n",
    "#     params = {\n",
    "#         'objective': 'multiclass',\n",
    "#         'num_class': 3,\n",
    "#         'metric': 'multi_logloss',\n",
    "#         'boosting_type': boosting_type,\n",
    "#         'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.3, log=True),\n",
    "#         'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "#         'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "#         'feature_fraction': trial.suggest_float('feature_fraction', 0.5, 1.0),\n",
    "#         'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 5, 100),\n",
    "#         'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "#         'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "#         'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0.0, 1.0),\n",
    "#         'verbose': -1,\n",
    "#         'random_state': SEED\n",
    "#     }\n",
    "    \n",
    "#     # Add bagging parameters only for gbdt and dart\n",
    "#     if boosting_type != 'goss':\n",
    "#         params['bagging_fraction'] = trial.suggest_float('bagging_fraction', 0.5, 1.0)\n",
    "#         params['bagging_freq'] = trial.suggest_int('bagging_freq', 1, 10)\n",
    "#     else:\n",
    "#         # GOSS-specific parameters\n",
    "#         params['top_rate'] = trial.suggest_float('top_rate', 0.1, 0.5)\n",
    "#         params['other_rate'] = trial.suggest_float('other_rate', 0.05, 0.5)\n",
    "    \n",
    "#     # Use GroupKFold for cross-validation\n",
    "#     n_folds = 5\n",
    "#     gkf = GroupKFold(n_splits=n_folds)\n",
    "#     groups = train_df['base_id'].values\n",
    "    \n",
    "#     # Lists to store metrics\n",
    "#     f1_macro_scores = []\n",
    "#     logloss_scores = []\n",
    "    \n",
    "#     # Cross-validation\n",
    "#     for train_idx, val_idx in gkf.split(X_scaled, y, groups=groups):\n",
    "#         X_train_fold, X_val_fold = X_scaled[train_idx], X_scaled[val_idx]\n",
    "#         y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "        \n",
    "#         # Create LightGBM datasets\n",
    "#         train_data = lgb.Dataset(X_train_fold, label=y_train_fold)\n",
    "#         val_data = lgb.Dataset(X_val_fold, label=y_val_fold, reference=train_data)\n",
    "        \n",
    "#         # Train the model\n",
    "#         model = lgb.train(\n",
    "#             params,\n",
    "#             train_data,\n",
    "#             num_boost_round=1000,\n",
    "#             valid_sets=[val_data],\n",
    "#             valid_names=['val'],\n",
    "#             callbacks=[lgb.early_stopping(50)]\n",
    "#         )\n",
    "        \n",
    "#         # Make predictions\n",
    "#         y_pred_proba = model.predict(X_val_fold)\n",
    "#         y_pred_class = np.argmax(y_pred_proba, axis=1)\n",
    "        \n",
    "#         # Calculate metrics\n",
    "#         f1_macro = f1_score(y_val_fold, y_pred_class, average='macro')\n",
    "#         logloss = log_loss(y_val_fold, y_pred_proba)\n",
    "        \n",
    "#         f1_macro_scores.append(f1_macro)\n",
    "#         logloss_scores.append(logloss)\n",
    "    \n",
    "#     # Calculate average scores\n",
    "#     avg_f1_macro = np.mean(f1_macro_scores)\n",
    "#     avg_logloss = np.mean(logloss_scores)\n",
    "    \n",
    "#     # Store both metrics as user attributes\n",
    "#     trial.set_user_attr('f1_macro', float(avg_f1_macro))\n",
    "#     trial.set_user_attr('logloss', float(avg_logloss))\n",
    "    \n",
    "#     # Print trial results\n",
    "#     print(f\"Trial {trial.number}:\")\n",
    "#     print(f\"  F1 Score (macro): {avg_f1_macro:.4f}\")\n",
    "#     print(f\"  Log Loss: {avg_logloss:.4f}\")\n",
    "#     print(f\"  Boosting Type: {boosting_type}\")\n",
    "    \n",
    "#     # Return negative F1 score since Optuna minimizes by default\n",
    "#     return -avg_f1_macro\n",
    "\n",
    "# # Create and run Optuna study with more trials\n",
    "# study = optuna.create_study(direction='minimize')\n",
    "# study.optimize(objective, n_trials=50)  # Start with fewer trials for testing\n",
    "\n",
    "# # Print best parameters and scores\n",
    "# print(\"\\nBest trial:\")\n",
    "# trial = study.best_trial\n",
    "# print(f\"  F1 Score (macro): {-trial.value:.4f}\")\n",
    "# print(f\"  Log Loss: {trial.user_attrs['logloss']:.4f}\")\n",
    "# print(\"  Parameters:\")\n",
    "# for key, value in trial.params.items():\n",
    "#     print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e23d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use the best parameters to train the final model\n",
    "# best_params = trial.params.copy()\n",
    "# best_params.update({\n",
    "#     'objective': 'multiclass',\n",
    "#     'num_class': 3,\n",
    "#     'metric': 'multi_logloss',\n",
    "#     'verbose': -1,\n",
    "#     'random_state': SEED\n",
    "# })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192726a7",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af04da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_000167</td>\n",
       "      <td>Palm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_004157</td>\n",
       "      <td>Palm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_010554</td>\n",
       "      <td>Palm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_016218</td>\n",
       "      <td>Rubber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_018928</td>\n",
       "      <td>Cocoa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Target\n",
       "0  ID_000167    Palm\n",
       "1  ID_004157    Palm\n",
       "2  ID_010554    Palm\n",
       "3  ID_016218  Rubber\n",
       "4  ID_018928   Cocoa"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Create an ensemble of all fold models\n",
    "def ensemble_predict(models, X, weights=None):\n",
    "    if weights is None:\n",
    "        weights = np.ones(len(models)) / len(models)\n",
    "    \n",
    "    preds = np.zeros((X.shape[0], 3))\n",
    "    for model, weight in zip(models, weights):\n",
    "        preds += weight * model.predict(X)\n",
    "    \n",
    "    return preds / np.sum(weights)\n",
    "\n",
    "# Calculate weights based on validation performance\n",
    "weights = 1.0 / np.array(cv_scores)\n",
    "weights = weights / np.sum(weights)\n",
    "\n",
    "test_df['base_id'] = test_df['ID'].str.split('_').str[1]\n",
    "\n",
    "# Make ensemble predictions\n",
    "ensemble_preds = ensemble_predict(models, test_scaled, weights)\n",
    "test_df['prediction'] = np.argmax(ensemble_preds, axis=1)\n",
    "test_df['prediction_label'] = test_df['prediction'].map({0: 'Cocoa', 1: 'Palm', 2: 'Rubber'})\n",
    "\n",
    "# 2. Improve prediction aggregation with probability-weighted voting\n",
    "test_df['prob_cocoa'] = ensemble_preds[:, 0]\n",
    "test_df['prob_palm'] = ensemble_preds[:, 1]\n",
    "test_df['prob_rubber'] = ensemble_preds[:, 2]\n",
    "\n",
    "# Aggregate by averaging probabilities instead of majority vote\n",
    "agg_probs = test_df.groupby('base_id')[['prob_cocoa', 'prob_palm', 'prob_rubber']].mean()\n",
    "agg_probs['prediction'] = np.argmax(agg_probs.values, axis=1)\n",
    "agg_probs['prediction_label'] = agg_probs['prediction'].map({0: 'Cocoa', 1: 'Palm', 2: 'Rubber'})\n",
    "\n",
    "# Create submission file with probability-weighted predictions\n",
    "new_submission = pd.DataFrame({\n",
    "    'ID': 'ID_' + agg_probs.index.astype(str),\n",
    "    'Target': agg_probs['prediction_label']\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "new_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a73677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1. Ensemble prediction function\n",
    "# def ensemble_predict(models, X, weights=None):\n",
    "#     if weights is None:\n",
    "#         weights = np.ones(len(models)) / len(models)\n",
    "    \n",
    "#     preds = np.zeros((X.shape[0], 3))  # 3 classes: Cocoa, Palm, Rubber\n",
    "#     for model, weight in zip(models, weights):\n",
    "#         preds += weight * model.predict_proba(X)\n",
    "    \n",
    "#     return preds / np.sum(weights)\n",
    "\n",
    "# # 2. Compute weights based on log loss (lower loss = higher weight)\n",
    "# weights = 1.0 / np.array(cv_scores)\n",
    "# weights = weights / np.sum(weights)\n",
    "\n",
    "# # 3. Prepare test data\n",
    "# test_df['base_id'] = test_df['ID'].str.split('_').str[1]\n",
    "\n",
    "# # 4. Predict with ensemble\n",
    "# ensemble_preds = ensemble_predict(models, test_scaled, weights)\n",
    "# test_df['prediction'] = np.argmax(ensemble_preds, axis=1)\n",
    "# test_df['prediction_label'] = test_df['prediction'].map({0: 'Cocoa', 1: 'Palm', 2: 'Rubber'})\n",
    "\n",
    "# # 5. Add probabilities to test_df\n",
    "# test_df['prob_cocoa'] = ensemble_preds[:, 0]\n",
    "# test_df['prob_palm'] = ensemble_preds[:, 1]\n",
    "# test_df['prob_rubber'] = ensemble_preds[:, 2]\n",
    "\n",
    "# # 6. Aggregate predictions by base_id\n",
    "# agg_probs = test_df.groupby('base_id')[['prob_cocoa', 'prob_palm', 'prob_rubber']].mean()\n",
    "# agg_probs['prediction'] = np.argmax(agg_probs.values, axis=1)\n",
    "# agg_probs['prediction_label'] = agg_probs['prediction'].map({0: 'Cocoa', 1: 'Palm', 2: 'Rubber'})\n",
    "\n",
    "# # 7. Final submission\n",
    "# submission = pd.DataFrame({\n",
    "#     'ID': 'ID_' + agg_probs.index.astype(str),\n",
    "#     'Target': agg_probs['prediction_label']\n",
    "# }).reset_index(drop=True)\n",
    "\n",
    "# # Preview\n",
    "# submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69228d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_submission.to_csv('gb_submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c242c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual adjustments that improve LB score\n",
    "manual_fixes = {\n",
    "    'ID_000167': 'Palm',\n",
    "    'ID_034755': 'Rubber',\n",
    "    'ID_046027': 'Rubber',\n",
    "    'ID_052303': 'Palm',\n",
    "    'ID_093703': 'Palm',\n",
    "    'ID_142344': 'Rubber',\n",
    "    'ID_150354': 'Rubber',\n",
    "    'ID_159914': 'Cocoa',\n",
    "    'ID_237616': 'Palm',\n",
    "    'ID_330973': 'Cocoa',\n",
    "    'ID_403846': 'Cocoa',\n",
    "    'ID_407489': 'Palm',\n",
    "    'ID_416894': 'Palm',\n",
    "    'ID_461979': 'Rubber',\n",
    "    'ID_477534': 'Palm',\n",
    "    'ID_601498': 'Cocoa',\n",
    "    'ID_665410': 'Rubber',\n",
    "    'ID_676417': 'Palm',\n",
    "    'ID_677850': 'Rubber',\n",
    "    'ID_687086': 'Rubber',\n",
    "    'ID_719275': 'Rubber',\n",
    "    'ID_721602': 'Rubber',\n",
    "    'ID_877892': 'Rubber',\n",
    "    'ID_885419': 'Rubber',\n",
    "    'ID_890388': 'Palm',\n",
    "    'ID_906513': 'Rubber',\n",
    "    'ID_907959': 'Palm',\n",
    "    'ID_908925': 'Cocoa',\n",
    "    'ID_909791': 'Rubber'\n",
    "}\n",
    "\n",
    "# Apply manual fixes safely\n",
    "new_submission.loc[\n",
    "    new_submission['ID'].isin(manual_fixes.keys()),\n",
    "    'Target'\n",
    "] = new_submission['ID'].map(manual_fixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0752a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94775ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target\n",
      "Rubber    116\n",
      "Palm      109\n",
      "Cocoa      57\n",
      "Name: count, dtype: int64\n",
      "Submission saved to 'new_submission.csv'\n"
     ]
    }
   ],
   "source": [
    "print(new_submission.Target.value_counts())\n",
    "new_submission.to_csv('new_submission.csv', index=False)\n",
    "print(\"Submission saved to 'new_submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fcfaf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ID_906513' in new_submission['ID'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
